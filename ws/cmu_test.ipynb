{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Proposed.models import Global_Scene_CAM_NFDecoder\n",
    "from Proposed.utils import ModelTest\n",
    "from dataset.nuscenes import NuscenesDataset, nuscenes_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_channels = 3\n",
    "sampling_rate = 2\n",
    "nfuture = int(3 * sampling_rate)\n",
    "\n",
    "velocity_const = 0.5\n",
    "agent_embed_dim = 128\n",
    "num_candidates = 6\n",
    "att_dropout = 0.1\n",
    "\n",
    "crossmodal_attention = False\n",
    "\n",
    "use_scene = True\n",
    "scene_size = (64, 64)\n",
    "ploss_type = 'map'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: {}\".format(device))\n",
    "\n",
    "model = Global_Scene_CAM_NFDecoder(device=device, agent_embed_dim=agent_embed_dim, nfuture=nfuture, att_dropout=att_dropout,\n",
    "                    velocity_const=velocity_const, num_candidates=num_candidates, decoding_steps=nfuture, att=crossmodal_attention)\n",
    "\n",
    "if ploss_type == 'mseloss':\n",
    "    from R2P2_MA.model_utils import MSE_Ploss\n",
    "    ploss_criterion = MSE_Ploss()\n",
    "else:\n",
    "    from R2P2_MA.model_utils import Interpolated_Ploss\n",
    "    ploss_criterion = Interpolated_Ploss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_partition = 'val'\n",
    "map_version = '2.0'\n",
    "sample_stride = 1\n",
    "multi_agent = 1\n",
    "num_workers = 20\n",
    "test_cache = \"./data/nuscenes_val_cache.pkl\"\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Examples: 5118\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "dataset = NuscenesDataset(\n",
    "    test_partition, map_version=map_version, sampling_rate=sampling_rate,\n",
    "    sample_stride=sample_stride, use_scene=use_scene, scene_size=scene_size, \n",
    "    ploss_type=ploss_type, num_workers=num_workers, \n",
    "    cache_file=test_cache, multi_agent=multi_agent)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, \n",
    "                         pin_memory=True,collate_fn=lambda x: nuscenes_collate(x), \n",
    "                         num_workers=1)\n",
    "\n",
    "print(f'Test Examples: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import logging\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_channels = 3\n",
    "sampling_rate = 2\n",
    "nfuture = int(3 * sampling_rate)\n",
    "\n",
    "velocity_const = 0.5\n",
    "agent_embed_dim = 128\n",
    "num_candidates = 6\n",
    "att_dropout = 0.1\n",
    "\n",
    "crossmodal_attention = False\n",
    "\n",
    "use_scene = True\n",
    "scene_size = (64, 64)\n",
    "ploss_type = 'map'\n",
    "\n",
    "test_partition = 'val'\n",
    "map_version = '2.0'\n",
    "sample_stride = 1\n",
    "multi_agent = 1\n",
    "num_workers = 20\n",
    "test_cache = \"./data/nuscenes_val_cache.pkl\"\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = 0.1\n",
    "decoding_steps = int(3 *  sampling_rate)\n",
    "model_type = \"Global_Scene_CAM_NFDecoder\"\n",
    "flow_based_decoder = True\n",
    "out_dir = \"./test\"\n",
    "\n",
    "test_ckpt = \"test.pth.tar\"\n",
    "\n",
    "\n",
    "test_render = 1\n",
    "test_times = 10\n",
    "render = test_render\n",
    "\n",
    "_data_dir = './data/nuscenes'\n",
    "map_file = lambda scene_id: [os.path.join(_data_dir, x[0], x[1], x[2], 'map/v1.3', x[3]) + '.pkl' for x in scene_id]\n",
    "\n",
    "\n",
    "checkpoint = torch.load(test_ckpt)\n",
    "model.load_state_dict(checkpoint['model_state'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dac(gen_trajs, map_file):\n",
    "    if '.png' in map_file:\n",
    "        map_array = cv2.imread(map_file, cv2.IMREAD_COLOR)\n",
    "\n",
    "    elif '.pkl' in map_file:\n",
    "        with open(map_file, 'rb') as pnt:\n",
    "            map_array = pkl.load(pnt)\n",
    "\n",
    "    da_mask = np.any(map_array > 0, axis=-1)\n",
    "\n",
    "    num_agents, num_candidates, decoding_timesteps = gen_trajs.shape[:3]\n",
    "    dac = []\n",
    "\n",
    "    gen_trajs = ((gen_trajs + 56) * 2).astype(np.int64)\n",
    "\n",
    "    stay_in_da_count = [0 for i in range(num_agents)]\n",
    "    for k in range(num_candidates):\n",
    "        gen_trajs_k = gen_trajs[:, k]\n",
    "\n",
    "        stay_in_da = [True for i in range(num_agents)]\n",
    "\n",
    "        oom_mask = np.any( np.logical_or(gen_trajs_k >= 224, gen_trajs_k < 0), axis=-1 )\n",
    "        diregard_mask = oom_mask.sum(axis=-1) > 2\n",
    "        for t in range(decoding_timesteps):\n",
    "            gen_trajs_kt = gen_trajs_k[:, t]\n",
    "            oom_mask_t = oom_mask[:, t]\n",
    "            x, y = gen_trajs_kt.T\n",
    "\n",
    "            lin_xy = (x*224+y)\n",
    "            lin_xy[oom_mask_t] = -1\n",
    "            for i in range(num_agents):\n",
    "                xi, yi = x[i], y[i]\n",
    "                _lin_xy = lin_xy.tolist()\n",
    "                lin_xyi = _lin_xy.pop(i)\n",
    "\n",
    "                if diregard_mask[i]:\n",
    "                    continue\n",
    "\n",
    "                if oom_mask_t[i]:\n",
    "                    continue\n",
    "\n",
    "                if not da_mask[yi, xi] or (lin_xyi in _lin_xy):\n",
    "                    stay_in_da[i] = False\n",
    "\n",
    "        for i in range(num_agents):\n",
    "            if stay_in_da[i]:\n",
    "                stay_in_da_count[i] += 1\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        if diregard_mask[i]:\n",
    "            dac.append(0.0)\n",
    "        else:\n",
    "            dac.append(stay_in_da_count[i] / num_candidates)\n",
    "\n",
    "    dac_mask = np.logical_not(diregard_mask)\n",
    "\n",
    "    return np.array(dac), dac_mask\n",
    "\n",
    "\n",
    "def dao(gen_trajs, map_file):\n",
    "    if '.png' in map_file:\n",
    "        map_array = cv2.imread(map_file, cv2.IMREAD_COLOR)\n",
    "\n",
    "    elif '.pkl' in map_file:\n",
    "        with open(map_file, 'rb') as pnt:\n",
    "            map_array = pkl.load(pnt)\n",
    "\n",
    "    da_mask = np.any(map_array > 0, axis=-1)\n",
    "\n",
    "    num_agents, num_candidates, decoding_timesteps = gen_trajs.shape[:3]\n",
    "    dao = [0 for i in range(num_agents)]\n",
    "\n",
    "    occupied = [[] for i in range(num_agents)]\n",
    "\n",
    "    gen_trajs = ((gen_trajs + 56) * 2).astype(np.int64)\n",
    "\n",
    "    for k in range(num_candidates):\n",
    "        gen_trajs_k = gen_trajs[:, k]\n",
    "\n",
    "        oom_mask = np.any( np.logical_or(gen_trajs_k >= 224, gen_trajs_k < 0), axis=-1 )\n",
    "        diregard_mask = oom_mask.sum(axis=-1) > 2\n",
    "\n",
    "        for t in range(decoding_timesteps):\n",
    "            gen_trajs_kt = gen_trajs_k[:, t]\n",
    "            oom_mask_t = oom_mask[:, t]\n",
    "            x, y = gen_trajs_kt.T\n",
    "\n",
    "            lin_xy = (x*224+y)\n",
    "            lin_xy[oom_mask_t] = -1\n",
    "            for i in range(num_agents):\n",
    "                xi, yi = x[i], y[i]\n",
    "                _lin_xy = lin_xy.tolist()\n",
    "                lin_xyi = _lin_xy.pop(i)\n",
    "\n",
    "                if diregard_mask[i]:\n",
    "                    continue\n",
    "\n",
    "                if oom_mask_t[i]:\n",
    "                    continue\n",
    "\n",
    "                if lin_xyi in occupied[i]:\n",
    "                    continue\n",
    "\n",
    "                if da_mask[yi, xi] and (lin_xyi not in _lin_xy):\n",
    "                    occupied[i].append(lin_xyi)\n",
    "                    dao[i] += 1\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        if diregard_mask[i]:\n",
    "            dao[i] = 0.0\n",
    "        else:\n",
    "            dao[i] /= da_mask.sum()\n",
    "\n",
    "    dao_mask = np.logical_not(diregard_mask)\n",
    "\n",
    "    return np.array(dao), dao_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_determinant(sigma):\n",
    "    det = sigma[:, :, 0, 0] * sigma[:, :, 1, 1] - sigma[:, :, 0, 1] ** 2\n",
    "    logdet = torch.log(det + 1e-9)\n",
    "\n",
    "    return logdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    print('Starting model test.....')\n",
    "    model.eval()  # Set model to evaluate mode.\n",
    "\n",
    "    list_loss = []\n",
    "    list_qloss = []\n",
    "    list_ploss = []\n",
    "    list_minade2, list_avgade2 = [], []\n",
    "    list_minfde2, list_avgfde2 = [], []\n",
    "    list_minade3, list_avgade3 = [], []\n",
    "    list_minfde3, list_avgfde3 = [], []\n",
    "    list_minmsd, list_avgmsd = [], []\n",
    "\n",
    "    list_dao = []\n",
    "    list_dac = []\n",
    "\n",
    "    for test_time_ in range(test_times):\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_qloss = 0.0\n",
    "        epoch_ploss = 0.0\n",
    "        epoch_minade2, epoch_avgade2 = 0.0, 0.0\n",
    "        epoch_minfde2, epoch_avgfde2 = 0.0, 0.0\n",
    "        epoch_minade3, epoch_avgade3 = 0.0, 0.0\n",
    "        epoch_minfde3, epoch_avgfde3 = 0.0, 0.0\n",
    "        epoch_minmsd, epoch_avgmsd = 0.0, 0.0\n",
    "        epoch_agents, epoch_agents2, epoch_agents3 = 0.0, 0.0, 0.0\n",
    "\n",
    "        epoch_dao = 0.0\n",
    "        epoch_dac = 0.0\n",
    "        dao_agents = 0.0\n",
    "        dac_agents = 0.0\n",
    "\n",
    "        H = W = 64\n",
    "        with torch.no_grad():\n",
    "            if map_version == '2.0':\n",
    "                coordinate_2d = np.indices((H, W))\n",
    "                coordinate = np.ravel_multi_index(coordinate_2d, dims=(H, W))\n",
    "                coordinate = torch.FloatTensor(coordinate)\n",
    "                coordinate = coordinate.reshape((1, 1, H, W))\n",
    "\n",
    "                coordinate_std, coordinate_mean = torch.std_mean(coordinate)\n",
    "                coordinate = (coordinate - coordinate_mean) / coordinate_std\n",
    "\n",
    "                distance_2d = coordinate_2d - np.array([(H-1)/2, (H-1)/2]).reshape((2, 1, 1))\n",
    "                distance = np.sqrt((distance_2d ** 2).sum(axis=0))\n",
    "                distance = torch.FloatTensor(distance)\n",
    "                distance = distance.reshape((1, 1, H, W))\n",
    "\n",
    "                distance_std, distance_mean = torch.std_mean(distance)\n",
    "                distance = (distance - distance_mean) / distance_std\n",
    "\n",
    "                coordinate = coordinate.to(device)\n",
    "                distance = distance.to(device)\n",
    "\n",
    "            c1 = -decoding_steps * np.log(2 * np.pi)\n",
    "\n",
    "\n",
    "\n",
    "            for b, batch in enumerate(data_loader):\n",
    "\n",
    "                scene_images, log_prior, \\\n",
    "                agent_masks, \\\n",
    "                num_src_trajs, src_trajs, src_lens, src_len_idx, \\\n",
    "                num_tgt_trajs, tgt_trajs, tgt_lens, tgt_len_idx, \\\n",
    "                tgt_two_mask, tgt_three_mask, \\\n",
    "                decode_start_vel, decode_start_pos, scene_id = batch\n",
    "\n",
    "                # Detect dynamic batch size\n",
    "                batch_size = scene_images.size(0)\n",
    "                num_three_agents = torch.sum(tgt_three_mask)\n",
    "\n",
    "                if map_version == '2.0':\n",
    "                    coordinate_batch = coordinate.repeat(batch_size, 1, 1, 1)\n",
    "                    distance_batch = distance.repeat(batch_size, 1, 1, 1)\n",
    "                    scene_images = torch.cat((scene_images.to(device), coordinate_batch, distance_batch), dim=1)\n",
    "\n",
    "                src_trajs = src_trajs.to(device)\n",
    "                src_lens = src_lens.to(device)\n",
    "\n",
    "                tgt_trajs = tgt_trajs.to(device)[tgt_three_mask]\n",
    "                tgt_lens = tgt_lens.to(device)[tgt_three_mask]\n",
    "\n",
    "                num_tgt_trajs = num_tgt_trajs.to(device)\n",
    "                episode_idx = torch.arange(batch_size, device=device).repeat_interleave(num_tgt_trajs)[tgt_three_mask]\n",
    "\n",
    "                agent_masks = agent_masks.to(device)\n",
    "                agent_tgt_three_mask = torch.zeros_like(agent_masks)\n",
    "                agent_masks_idx = torch.arange(len(agent_masks), device=device)[agent_masks][tgt_three_mask]\n",
    "                agent_tgt_three_mask[agent_masks_idx] = True\n",
    "\n",
    "                decode_start_vel = decode_start_vel.to(device)[agent_tgt_three_mask]\n",
    "                decode_start_pos = decode_start_pos.to(device)[agent_tgt_three_mask]\n",
    "\n",
    "                log_prior = log_prior.to(device)\n",
    "\n",
    "                if flow_based_decoder:\n",
    "                    # Normalizing Flow (q loss)\n",
    "                    # z: A X Td X 2\n",
    "                    # mu: A X Td X 2\n",
    "                    # sigma: A X Td X 2 X 2\n",
    "                    # Generate perturbation\n",
    "                    perterb = torch.normal(mean=0.0, std=np.sqrt(0.001), size=tgt_trajs.shape, device=device)\n",
    "\n",
    "                    if model_type == 'R2P2_SimpleRNN':\n",
    "                        z_, mu_, sigma_, motion_encoding_ = model.infer(tgt_trajs+perterb, src_trajs, decode_start_vel, decode_start_pos)\n",
    "\n",
    "                    elif model_type == 'R2P2_RNN':\n",
    "                        z_, mu_, sigma_, motion_encoding_, scene_encoding_ = model.infer(tgt_trajs+perterb, src_trajs, episode_idx, decode_start_vel, decode_start_pos, scene_images)\n",
    "\n",
    "                    elif model_type == 'CAM_NFDecoder':\n",
    "                        z_, mu_, sigma_, motion_encoding_ = model.infer(tgt_trajs+perterb, src_trajs, src_lens, agent_tgt_three_mask, decode_start_vel, decode_start_pos, num_src_trajs)\n",
    "\n",
    "                    elif model_type == 'Scene_CAM_NFDecoder':\n",
    "                        z_, mu_, sigma_, motion_encoding_, scene_encoding_ = model.infer(tgt_trajs+perterb, src_trajs, src_lens, agent_tgt_three_mask, episode_idx, decode_start_vel, decode_start_pos, num_src_trajs, scene_images)\n",
    "\n",
    "                    elif model_type == 'Global_Scene_CAM_NFDecoder':\n",
    "                        z_, mu_, sigma_, motion_encoding_, scene_encoding_ = model.infer(tgt_trajs+perterb, src_trajs, src_lens, agent_tgt_three_mask, episode_idx, decode_start_vel, decode_start_pos, num_src_trajs, scene_images)\n",
    "\n",
    "                    elif model_type == 'AttGlobal_Scene_CAM_NFDecoder':\n",
    "                        z_, mu_, sigma_, motion_encoding_, scene_encoding_ = model.infer(tgt_trajs+perterb, src_trajs, src_lens, agent_tgt_three_mask, episode_idx, decode_start_vel, decode_start_pos, num_src_trajs, scene_images)\n",
    "\n",
    "                    z_ = z_.reshape((num_three_agents, -1)) # A X (Td*2)\n",
    "                    log_q0 = c1 - 0.5 * ((z_ ** 2).sum(dim=1))\n",
    "\n",
    "                    logdet_sigma = log_determinant(sigma_)\n",
    "\n",
    "                    log_qpi = log_q0 - logdet_sigma.sum(dim=1)\n",
    "                    qloss = -log_qpi\n",
    "                    batch_qloss = qloss.mean()\n",
    "\n",
    "                    # Prior Loss (p loss)\n",
    "                    if model_type == 'R2P2_SimpleRNN':\n",
    "                        gen_trajs, z, mu, sigma = model(motion_encoding_, decode_start_vel, decode_start_pos, motion_encoded=True)\n",
    "\n",
    "                    elif model_type == 'R2P2_RNN':\n",
    "                        gen_trajs, z, mu, sigma = model(motion_encoding_, episode_idx, decode_start_vel, decode_start_pos, scene_encoding_, motion_encoded=True, scene_encoded=True)\n",
    "\n",
    "                    elif model_type == 'CAM_NFDecoder':\n",
    "                        gen_trajs, z, mu, sigma = model(motion_encoding_, src_lens, agent_tgt_three_mask, decode_start_vel, decode_start_pos, num_src_trajs, agent_encoded=True)\n",
    "\n",
    "                    elif model_type == 'Scene_CAM_NFDecoder':\n",
    "                        gen_trajs, z, mu, sigma = model(motion_encoding_, src_lens, agent_tgt_three_mask, episode_idx, decode_start_vel, decode_start_pos, num_src_trajs, scene_encoding_, agent_encoded=True, scene_encoded=True)\n",
    "\n",
    "                    elif model_type == 'Global_Scene_CAM_NFDecoder':\n",
    "                        gen_trajs, z, mu, sigma = model(motion_encoding_, src_lens, agent_tgt_three_mask, episode_idx, decode_start_vel, decode_start_pos, num_src_trajs, scene_encoding_, agent_encoded=True, scene_encoded=True)\n",
    "\n",
    "                    elif model_type == 'AttGlobal_Scene_CAM_NFDecoder':\n",
    "                        gen_trajs, z, mu, sigma = model(motion_encoding_, src_lens, agent_tgt_three_mask, episode_idx, decode_start_vel, decode_start_pos, num_src_trajs, scene_encoding_, agent_encoded=True, scene_encoded=True)\n",
    "\n",
    "                    if beta != 0.0:\n",
    "                        if ploss_type == 'mseloss':\n",
    "                            ploss = ploss_criterion(gen_trajs, tgt_trajs)\n",
    "                        else:\n",
    "                            ploss = ploss_criterion(episode_idx, gen_trajs, log_prior, -15.0)\n",
    "\n",
    "                    else:\n",
    "                        ploss = torch.zeros(size=(1,), device=device)\n",
    "                    batch_ploss = ploss.mean()\n",
    "                    batch_loss = batch_qloss + beta * batch_ploss\n",
    "\n",
    "                    epoch_ploss += batch_ploss.item() * batch_size\n",
    "                    epoch_qloss += batch_qloss.item() * batch_size   \n",
    "\n",
    "                else:\n",
    "\n",
    "                    if 'CAM' == model_type:\n",
    "                        gen_trajs = model(src_trajs, src_lens, agent_tgt_three_mask, decode_start_vel, decode_start_pos, num_src_trajs)                                                    \n",
    "\n",
    "                    gen_trajs = gen_trajs.reshape(num_three_agents, num_candidates, decoding_steps, 2)\n",
    "\n",
    "\n",
    "                rs_error3 = ((gen_trajs - tgt_trajs.unsqueeze(1)) ** 2).sum(dim=-1).sqrt_()\n",
    "                rs_error2 = rs_error3[..., :int(decoding_steps*2/3)]\n",
    "\n",
    "\n",
    "                diff = gen_trajs - tgt_trajs.unsqueeze(1)\n",
    "                msd_error = (diff[:,:,:,0] ** 2 + diff[:,:,:,1] ** 2)\n",
    "\n",
    "                num_agents = gen_trajs.size(0)\n",
    "                num_agents2 = rs_error2.size(0)\n",
    "                num_agents3 = rs_error3.size(0)\n",
    "\n",
    "                ade2 = rs_error2.mean(-1)\n",
    "                fde2 = rs_error2[..., -1]\n",
    "\n",
    "                minade2, _ = ade2.min(dim=-1)\n",
    "                avgade2 = ade2.mean(dim=-1)\n",
    "                minfde2, _ = fde2.min(dim=-1)\n",
    "                avgfde2 = fde2.mean(dim=-1)\n",
    "\n",
    "                batch_minade2 = minade2.mean()\n",
    "                batch_minfde2 = minfde2.mean()\n",
    "                batch_avgade2 = avgade2.mean()\n",
    "                batch_avgfde2 = avgfde2.mean()\n",
    "\n",
    "                ade3 = rs_error3.mean(-1)\n",
    "                fde3 = rs_error3[..., -1]\n",
    "\n",
    "\n",
    "                msd = msd_error.mean(-1)\n",
    "                minmsd, _ = msd.min(dim=-1)\n",
    "                avgmsd = msd.mean(dim=-1)\n",
    "                batch_minmsd = minmsd.mean()\n",
    "                batch_avgmsd = avgmsd.mean()\n",
    "\n",
    "\n",
    "                minade3, _ = ade3.min(dim=-1)\n",
    "                avgade3 = ade3.mean(dim=-1)\n",
    "                minfde3, _ = fde3.min(dim=-1)\n",
    "                avgfde3 = fde3.mean(dim=-1)\n",
    "\n",
    "                batch_minade3 = minade3.mean()\n",
    "                batch_minfde3 = minfde3.mean()\n",
    "                batch_avgade3 = avgade3.mean()\n",
    "                batch_avgfde3 = avgfde3.mean()\n",
    "\n",
    "                if flow_based_decoder is not True:\n",
    "                    batch_loss = batch_minade3\n",
    "                    epoch_loss += batch_loss.item()\n",
    "                    batch_qloss = torch.zeros(1)\n",
    "                    batch_ploss = torch.zeros(1)\n",
    "\n",
    "                print(\"Working on test {:d}/{:d}, batch {:d}/{:d}... \".format(test_time_+1, test_times, b+1, len(data_loader)), end='\\r')# +\n",
    "\n",
    "                epoch_ploss += batch_ploss.item() * batch_size\n",
    "                epoch_qloss += batch_qloss.item() * batch_size\n",
    "                epoch_minade2 += batch_minade2.item() * num_agents2\n",
    "                epoch_avgade2 += batch_avgade2.item() * num_agents2\n",
    "                epoch_minfde2 += batch_minfde2.item() * num_agents2\n",
    "                epoch_avgfde2 += batch_avgfde2.item() * num_agents2\n",
    "                epoch_minade3 += batch_minade3.item() * num_agents3\n",
    "                epoch_avgade3 += batch_avgade3.item() * num_agents3\n",
    "                epoch_minfde3 += batch_minfde3.item() * num_agents3\n",
    "                epoch_avgfde3 += batch_avgfde3.item() * num_agents3\n",
    "\n",
    "\n",
    "                epoch_minmsd += batch_minmsd.item() * num_agents3\n",
    "                epoch_avgmsd += batch_avgmsd.item() * num_agents3\n",
    "\n",
    "                epoch_agents += num_agents\n",
    "                epoch_agents2 += num_agents2\n",
    "                epoch_agents3 += num_agents3\n",
    "\n",
    "                map_files = map_file(scene_id)\n",
    "                output_files = [out_dir + '/' + x[2] + '_' + x[3] + '.jpg' for x in scene_id]\n",
    "\n",
    "                cum_num_tgt_trajs = [0] + torch.cumsum(num_tgt_trajs, dim=0).tolist()\n",
    "                cum_num_src_trajs = [0] + torch.cumsum(num_src_trajs, dim=0).tolist()\n",
    "\n",
    "                src_trajs = src_trajs.cpu().numpy()\n",
    "                src_lens = src_lens.cpu().numpy()\n",
    "\n",
    "                tgt_trajs = tgt_trajs.cpu().numpy()\n",
    "                tgt_lens = tgt_lens.cpu().numpy()\n",
    "\n",
    "                zero_ind = np.nonzero(tgt_three_mask.numpy() == 0)[0]\n",
    "                zero_ind -= np.arange(len(zero_ind))\n",
    "\n",
    "                tgt_three_mask = tgt_three_mask.numpy()\n",
    "                agent_tgt_three_mask = agent_tgt_three_mask.cpu().numpy()\n",
    "\n",
    "                gen_trajs = gen_trajs.cpu().numpy()\n",
    "\n",
    "                src_mask = agent_tgt_three_mask\n",
    "\n",
    "                gen_trajs = np.insert(gen_trajs, zero_ind, 0, axis=0)\n",
    "\n",
    "                tgt_trajs = np.insert(tgt_trajs, zero_ind, 0, axis=0)\n",
    "                tgt_lens = np.insert(tgt_lens, zero_ind, 0, axis=0)\n",
    "\n",
    "                for i in range(batch_size):\n",
    "                    candidate_i = gen_trajs[cum_num_tgt_trajs[i]:cum_num_tgt_trajs[i+1]]\n",
    "                    tgt_traj_i = tgt_trajs[cum_num_tgt_trajs[i]:cum_num_tgt_trajs[i+1]]\n",
    "                    tgt_lens_i = tgt_lens[cum_num_tgt_trajs[i]:cum_num_tgt_trajs[i+1]]\n",
    "\n",
    "                    src_traj_i = src_trajs[cum_num_src_trajs[i]:cum_num_src_trajs[i+1]]\n",
    "                    src_lens_i = src_lens[cum_num_src_trajs[i]:cum_num_src_trajs[i+1]]\n",
    "                    map_file_i = map_files[i]\n",
    "                    output_file_i = output_files[i]\n",
    "\n",
    "                    candidate_i = candidate_i[tgt_three_mask[cum_num_tgt_trajs[i]:cum_num_tgt_trajs[i+1]]]\n",
    "                    tgt_traj_i = tgt_traj_i[tgt_three_mask[cum_num_tgt_trajs[i]:cum_num_tgt_trajs[i+1]]]\n",
    "                    tgt_lens_i = tgt_lens_i[tgt_three_mask[cum_num_tgt_trajs[i]:cum_num_tgt_trajs[i+1]]]\n",
    "\n",
    "                    src_traj_i = src_traj_i[agent_tgt_three_mask[cum_num_src_trajs[i]:cum_num_src_trajs[i+1]]]\n",
    "                    src_lens_i = src_lens_i[agent_tgt_three_mask[cum_num_src_trajs[i]:cum_num_src_trajs[i+1]]]\n",
    "\n",
    "                    dao_i, dao_mask_i = dao(candidate_i, map_file_i)\n",
    "                    dac_i, dac_mask_i = dac(candidate_i, map_file_i)\n",
    "\n",
    "                    epoch_dao += dao_i.sum()\n",
    "                    dao_agents += dao_mask_i.sum()\n",
    "\n",
    "                    epoch_dac += dac_i.sum()\n",
    "                    dac_agents += dac_mask_i.sum()\n",
    "                    \n",
    "                    write_img_output(candidate_i, src_traj_i, src_lens_i, tgt_traj_i, tgt_lens_i, map_file_i, 'test/img')\n",
    "#                     time.sleep(1)\n",
    "                    \n",
    "                    \n",
    "\n",
    "#                 write_img_output(gen_trajs, src_trajs, src_lens, tgt_trajs, tgt_lens, map_files, 'test/img')\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        if flow_based_decoder:\n",
    "            list_ploss.append(epoch_ploss / epoch_agents)\n",
    "            list_qloss.append(epoch_qloss / epoch_agents)\n",
    "            list_loss.append(epoch_qloss + beta * epoch_ploss)\n",
    "\n",
    "        else:\n",
    "            list_loss.append(epoch_loss / epoch_agents)\n",
    "\n",
    "        # 2-Loss\n",
    "        list_minade2.append(epoch_minade2 / epoch_agents2)\n",
    "        list_avgade2.append(epoch_avgade2 / epoch_agents2)\n",
    "        list_minfde2.append(epoch_minfde2 / epoch_agents2)\n",
    "        list_avgfde2.append(epoch_avgfde2 / epoch_agents2)\n",
    "\n",
    "        # 3-Loss\n",
    "        list_minade3.append(epoch_minade3 / epoch_agents3)\n",
    "        list_avgade3.append(epoch_avgade3 / epoch_agents3)\n",
    "        list_minfde3.append(epoch_minfde3 / epoch_agents3)\n",
    "        list_avgfde3.append(epoch_avgfde3 / epoch_agents3)\n",
    "\n",
    "        list_minmsd.append(epoch_minmsd / epoch_agents3)\n",
    "        list_avgmsd.append(epoch_avgmsd / epoch_agents3)\n",
    "\n",
    "        list_dao.append(epoch_dao / dao_agents)\n",
    "        list_dac.append(epoch_dac / dac_agents)\n",
    "\n",
    "    if flow_based_decoder:\n",
    "        test_ploss = [np.mean(list_ploss), np.std(list_ploss)]\n",
    "        test_qloss = [np.mean(list_qloss), np.std(list_qloss)]\n",
    "        test_loss = [np.mean(list_loss), np.std(list_loss)]\n",
    "\n",
    "    else:\n",
    "        test_ploss = [0.0, 0.0]\n",
    "        test_qloss = [0.0, 0.0]\n",
    "        test_loss = [np.mean(list_loss), np.std(list_loss)]\n",
    "\n",
    "    test_minade2 = [np.mean(list_minade2), np.std(list_minade2)]\n",
    "    test_avgade2 = [np.mean(list_avgade2), np.std(list_avgade2)]\n",
    "    test_minfde2 = [np.mean(list_minfde2), np.std(list_minfde2)]\n",
    "    test_avgfde2 = [np.mean(list_avgfde2), np.std(list_avgfde2)]\n",
    "\n",
    "    test_minade3 = [np.mean(list_minade3), np.std(list_minade3)]\n",
    "    test_avgade3 = [np.mean(list_avgade3), np.std(list_avgade3)]\n",
    "    test_minfde3 = [np.mean(list_minfde3), np.std(list_minfde3)]\n",
    "    test_avgfde3 = [np.mean(list_avgfde3), np.std(list_avgfde3)]\n",
    "\n",
    "    test_minmsd = [np.mean(list_minmsd), np.std(list_minmsd)]\n",
    "    test_avgmsd = [np.mean(list_avgmsd), np.std(list_avgmsd)]\n",
    "\n",
    "    test_dao = [np.mean(list_dao), np.std(list_dao)]\n",
    "    test_dac = [np.mean(list_dac), np.std(list_dac)]\n",
    "\n",
    "    test_ades = ( test_minade2, test_avgade2, test_minade3, test_avgade3 )\n",
    "    test_fdes = ( test_minfde2, test_avgfde2, test_minfde3, test_avgfde3 )\n",
    "\n",
    "    print(\"--Final Performane Report--\")\n",
    "    print(\"minADE3: {:.5f}±{:.5f}, minFDE3: {:.5f}±{:.5f}\".format(test_minade3[0], test_minade3[1], test_minfde3[0], test_minfde3[1]))\n",
    "    print(\"avgADE3: {:.5f}±{:.5f}, avgFDE3: {:.5f}±{:.5f}\".format(test_avgade3[0], test_avgade3[1], test_avgfde3[0], test_avgfde3[1]))\n",
    "    print(\"DAO: {:.5f}±{:.5f}, DAC: {:.5f}±{:.5f}\".format(test_dao[0] * 10000.0, test_dao[1] * 10000.0, test_dac[0], test_dac[1]))\n",
    "    with open(out_dir + '/metric.pkl', 'wb') as f:\n",
    "        pkl.dump({\"ADEs\": test_ades,\n",
    "                  \"FDEs\": test_fdes,\n",
    "                  \"Qloss\": test_qloss,\n",
    "                  \"Ploss\": test_ploss, \n",
    "                  \"DAO\": test_dao,\n",
    "                  \"DAC\": test_dac}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_img_output_(gen_trajs, src_trajs, src_lens, tgt_trajs, tgt_lens, map_file, output_file):\n",
    "    if '.png' in map_file:\n",
    "        map_array = cv2.imread(map_file, cv2.IMREAD_COLOR)\n",
    "        map_array = cv2.cvtColor(map_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    elif '.pkl' in map_file:\n",
    "        with open(map_file, 'rb') as pnt:\n",
    "            map_array = pkl.load(pnt)\n",
    "    \n",
    "    H, W = map_array.shape[:2]\n",
    "    fig = plt.figure(figsize=(float(H) / float(80), float(W) / float(80)),\n",
    "                    facecolor='k', dpi=80)\n",
    "\n",
    "    ax = plt.axes()\n",
    "    ax.imshow(map_array, extent=[-56, 56, 56, -56])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim([-56, 56])\n",
    "    ax.set_ylim([-56, 56])\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "                        hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "\n",
    "    num_tgt_agents, num_candidates = gen_trajs.shape[:2]\n",
    "    num_src_agents = len(src_trajs)\n",
    "\n",
    "    for k in range(num_candidates):\n",
    "        gen_trajs_k = gen_trajs[:, k]\n",
    "\n",
    "        x_pts_k = []\n",
    "        y_pts_k = []\n",
    "        for i in range(num_tgt_agents):\n",
    "            gen_traj_ki = gen_trajs_k[i]\n",
    "            tgt_len_i = tgt_lens[i]\n",
    "            x_pts_k.extend(gen_traj_ki[:tgt_len_i, 0])\n",
    "            y_pts_k.extend(gen_traj_ki[:tgt_len_i, 1])\n",
    "\n",
    "        ax.scatter(x_pts_k, y_pts_k, s=0.5, marker='o', c='b')\n",
    "\n",
    "    x_pts = []\n",
    "    y_pts = []\n",
    "    for i in range(num_src_agents):\n",
    "            src_traj_i = src_trajs[i]\n",
    "            src_len_i = src_lens[i]\n",
    "            x_pts.extend(src_traj_i[:src_len_i, 0])\n",
    "            y_pts.extend(src_traj_i[:src_len_i, 1])\n",
    "\n",
    "    ax.scatter(x_pts, y_pts, s=2.0, marker='x', c='g')\n",
    "\n",
    "    x_pts = []\n",
    "    y_pts = []\n",
    "    for i in range(num_tgt_agents):\n",
    "            tgt_traj_i = tgt_trajs[i]\n",
    "            tgt_len_i = tgt_lens[i]\n",
    "            x_pts.extend(tgt_traj_i[:tgt_len_i, 0])\n",
    "            y_pts.extend(tgt_traj_i[:tgt_len_i, 1])\n",
    "\n",
    "    ax.scatter(x_pts, y_pts, s=2.0, marker='o', c='r')\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    buffer = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    buffer = buffer.reshape((H, W, 3))\n",
    "\n",
    "    buffer = cv2.cvtColor(buffer, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(output_file+'file.png', buffer)\n",
    "    ax.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_img_output1(gen_trajs, src_trajs, src_lens, tgt_trajs, tgt_lens, map_file, output_file):\n",
    "    if '.png' in map_file:\n",
    "        map_array = cv2.imread(map_file, cv2.IMREAD_COLOR)\n",
    "        map_array = cv2.cvtColor(map_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    elif '.pkl' in map_file:\n",
    "        with open(map_file, 'rb') as pnt:\n",
    "            map_array = pkl.load(pnt)\n",
    "    \n",
    "    H, W = map_array.shape[:2]\n",
    "#     fig, ax = plt.subplots(1, 1, facecolor='k')\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    \n",
    "    \n",
    "    ax.set_title(\"Inference\")\n",
    "    ax.imshow(map_array, extent=[-56, 56, 56, -56])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim([-56, 56])\n",
    "    ax.set_ylim([-56, 56])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "\n",
    "    num_tgt_agents, num_candidates = gen_trajs.shape[:2]\n",
    "    num_src_agents = len(src_trajs)\n",
    "\n",
    "    for k in range(num_candidates):\n",
    "        gen_trajs_k = gen_trajs[:, k]\n",
    "\n",
    "        x_pts_k = []\n",
    "        y_pts_k = []\n",
    "        for i in range(num_tgt_agents):\n",
    "            gen_traj_ki = gen_trajs_k[i]\n",
    "            tgt_len_i = tgt_lens[i]\n",
    "            x_pts_k.extend(gen_traj_ki[:tgt_len_i, 0])\n",
    "            y_pts_k.extend(gen_traj_ki[:tgt_len_i, 1])\n",
    "\n",
    "#         ax.scatter(x_pts_k, y_pts_k, s=0.5, marker='o', c='b')\n",
    "        ax.scatter(x_pts_k, y_pts_k, label='generated')\n",
    "\n",
    "    x_pts = []\n",
    "    y_pts = []\n",
    "    for i in range(num_src_agents):\n",
    "            src_traj_i = src_trajs[i]\n",
    "            src_len_i = src_lens[i]\n",
    "            x_pts.extend(src_traj_i[:src_len_i, 0])\n",
    "            y_pts.extend(src_traj_i[:src_len_i, 1])\n",
    "\n",
    "#     ax.scatter(x_pts, y_pts, s=2.0, marker='x', c='g')\n",
    "    ax.scatter(x_pts, y_pts, label='source')\n",
    "\n",
    "    x_pts = []\n",
    "    y_pts = []\n",
    "    for i in range(num_tgt_agents):\n",
    "            tgt_traj_i = tgt_trajs[i]\n",
    "            tgt_len_i = tgt_lens[i]\n",
    "            x_pts.extend(tgt_traj_i[:tgt_len_i, 0])\n",
    "            y_pts.extend(tgt_traj_i[:tgt_len_i, 1])\n",
    "\n",
    "#     ax.scatter(x_pts, y_pts, s=2.0, marker='o', c='r')\n",
    "    ax.scatter(x_pts, y_pts, label='target')\n",
    "    \n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_img_output2(gen_trajs, src_trajs, src_lens, tgt_trajs, tgt_lens, map_file, output_file):\n",
    "    if '.png' in map_file:\n",
    "        map_array = cv2.imread(map_file, cv2.IMREAD_COLOR)\n",
    "        map_array = cv2.cvtColor(map_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    elif '.pkl' in map_file:\n",
    "        with open(map_file, 'rb') as pnt:\n",
    "            map_array = pkl.load(pnt)\n",
    "    \n",
    "    \n",
    "    def plot_candidate(title, ax, can_idx):\n",
    "        ax.set_title(title)\n",
    "        ax.imshow(map_array, extent=[-56, 56, 56, -56])\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_xlim([-56, 56])\n",
    "        ax.set_ylim([-56, 56])\n",
    "        \n",
    "        num_tgt_agents, num_candidates = gen_trajs.shape[:2]\n",
    "        num_src_agents = len(src_trajs)\n",
    "\n",
    "        gen_trajs_k = gen_trajs[:, can_idx]\n",
    "        \n",
    "        x_pts_k, y_pts_k = [], []\n",
    "        for i in range(num_tgt_agents):\n",
    "            gen_traj_ki = gen_trajs_k[i]\n",
    "            tgt_len_i = tgt_lens[i]\n",
    "            x_pts_k.extend(gen_traj_ki[:tgt_len_i, 0])\n",
    "            y_pts_k.extend(gen_traj_ki[:tgt_len_i, 1])\n",
    "#         print(\"num_tgt_agents: {}\".format(num_tgt_agents))\n",
    "        ax.plot(x_pts_k, y_pts_k, label='generated')\n",
    "\n",
    "        x_pts, y_pts = [], []\n",
    "        for i in range(num_src_agents):\n",
    "                src_traj_i = src_trajs[i]\n",
    "                src_len_i = src_lens[i]\n",
    "                x_pts.extend(src_traj_i[:src_len_i, 0])\n",
    "                y_pts.extend(src_traj_i[:src_len_i, 1])\n",
    "        print(\"num_src_agents: {}\".format(num_src_agents))\n",
    "        ax.scatter(x_pts, y_pts, label='source', alpha=0.3)\n",
    "\n",
    "        x_pts, y_pts = [], []\n",
    "        for i in range(num_tgt_agents):\n",
    "                tgt_traj_i = tgt_trajs[i]\n",
    "                tgt_len_i = tgt_lens[i]\n",
    "                x_pts.extend(tgt_traj_i[:tgt_len_i, 0])\n",
    "                y_pts.extend(tgt_traj_i[:tgt_len_i, 1])\n",
    "        print(\"num_tgt_agents: {}\".format(num_tgt_agents))\n",
    "        ax.scatter(x_pts, y_pts, label='target', alpha=0.3)\n",
    "        ax.legend()\n",
    "        \n",
    "        \n",
    "    H, W = map_array.shape[:2]\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(18,6))\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.gca().set_axis_off()\n",
    "    \n",
    "    \n",
    "    for a in range(2):\n",
    "        for b in range(3):\n",
    "            num = 3*a + b\n",
    "            plot_candidate('Inference {}'.format(num+1), ax[a][b], num)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_img_output(gen_trajs, src_trajs, src_lens, tgt_trajs, tgt_lens, map_file, output_file):\n",
    "    if '.png' in map_file:\n",
    "        map_array = cv2.imread(map_file, cv2.IMREAD_COLOR)\n",
    "        map_array = cv2.cvtColor(map_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    elif '.pkl' in map_file:\n",
    "        with open(map_file, 'rb') as pnt:\n",
    "            map_array = pkl.load(pnt)\n",
    "    \n",
    "    \n",
    "    def plot_candidate(title, ax, can_idx):\n",
    "        ax.set_title(title)\n",
    "        ax.imshow(map_array, extent=[-56, 56, 56, -56])\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_xlim([-56, 56])\n",
    "        ax.set_ylim([-56, 56])\n",
    "        \n",
    "        num_tgt_agents, num_candidates = gen_trajs.shape[:2]\n",
    "        num_src_agents = len(src_trajs)\n",
    "\n",
    "        gen_trajs_k = gen_trajs[:, can_idx]\n",
    "        \n",
    "        x_pts_k, y_pts_k = [], []\n",
    "        for i in range(num_tgt_agents):\n",
    "            gen_traj_ki = gen_trajs_k[i]\n",
    "            tgt_len_i = tgt_lens[i]\n",
    "            x_pts_k.extend(gen_traj_ki[:tgt_len_i, 0])\n",
    "            y_pts_k.extend(gen_traj_ki[:tgt_len_i, 1])\n",
    "            ax.plot(gen_traj_ki[:tgt_len_i, 0], gen_traj_ki[:tgt_len_i, 1], c='g', linewidth=3.5)\n",
    "\n",
    "        x_pts, y_pts = [], []\n",
    "        for i in range(num_src_agents):\n",
    "                src_traj_i = src_trajs[i]\n",
    "                src_len_i = src_lens[i]\n",
    "                x_pts.extend(src_traj_i[:src_len_i, 0])\n",
    "                y_pts.extend(src_traj_i[:src_len_i, 1])\n",
    "                ax.plot(src_traj_i[:src_len_i, 0], src_traj_i[:src_len_i, 1], alpha=0.3, c='orange', linewidth=3.5)\n",
    "\n",
    "        x_pts, y_pts = [], []\n",
    "        for i in range(num_tgt_agents):\n",
    "                tgt_traj_i = tgt_trajs[i]\n",
    "                tgt_len_i = tgt_lens[i]\n",
    "                x_pts.extend(tgt_traj_i[:tgt_len_i, 0])\n",
    "                y_pts.extend(tgt_traj_i[:tgt_len_i, 1])\n",
    "                ax.plot(tgt_traj_i[:tgt_len_i, 0], tgt_traj_i[:tgt_len_i, 1], alpha=0.3, c='r', linewidth=3.5)\n",
    "        \n",
    "        ax.plot([], [], c='r', alpha=0.3, label='ground-truth')\n",
    "        ax.plot([], [], c='orange', alpha=0.3, label='history')\n",
    "        ax.plot([], [], c='g', label='estimated')\n",
    "        ax.legend()\n",
    "        \n",
    "        \n",
    "    H, W = map_array.shape[:2]\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(18,12))\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     plt.gca().set_axis_off()\n",
    "    \n",
    "    \n",
    "    for a in range(2):\n",
    "        for b in range(3):\n",
    "            num = 3*a + b\n",
    "            plot_candidate('Inference {}'.format(num+1), ax[a][b], num)\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "    global img_save_count\n",
    "    \n",
    "    fig.savefig('./test/results/scene_{}.jpg'.format(img_save_count), bbox_inches='tight', pad_inches=0.5, dpi=150)\n",
    "    img_save_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model test.....\n",
      "Working on test 1/10, batch 1/80... \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q10/.pyenv/versions/intelpro/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/q10/.pyenv/versions/intelpro/lib/python3.7/site-packages/ipykernel_launcher.py:54: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    }
   ],
   "source": [
    "img_save_count = 0\n",
    "\n",
    "run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelpro",
   "language": "python",
   "name": "intelpro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
