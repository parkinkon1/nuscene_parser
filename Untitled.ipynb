{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pky\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pky\n",
    "    del pky\n",
    "    print(\"reimport pky\")\n",
    "except:\n",
    "    print(\"import pky\")\n",
    "import pkyutils as pky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 형식 맞추기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) CMU 데이터 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Examples: 5118\n"
     ]
    }
   ],
   "source": [
    "dataset_cmu, data_loader_cmu = pky.load_CMU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_images, log_prior, \\\n",
    "    agent_masks, \\\n",
    "    num_src_trajs, src_trajs, src_lens, src_len_idx, \\\n",
    "    num_tgt_trajs, tgt_trajs, tgt_lens, tgt_len_idx, \\\n",
    "    tgt_two_mask, tgt_three_mask, \\\n",
    "    decode_start_vel, decode_start_pos, scene_id = np.arange(16)\n",
    "\n",
    "for b, batch in enumerate(data_loader_cmu):\n",
    "    scene_images, log_prior, \\\n",
    "    agent_masks, \\\n",
    "    num_src_trajs, src_trajs, src_lens, src_len_idx, \\\n",
    "    num_tgt_trajs, tgt_trajs, tgt_lens, tgt_len_idx, \\\n",
    "    tgt_two_mask, tgt_three_mask, \\\n",
    "    decode_start_vel, decode_start_pos, scene_id = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 커스텀 데이터 형식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.317 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n",
      "num_samples: 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q10/.pyenv/versions/intelpro/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "pkyLoader = pky.CustomLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkyLoader.load_data(0, None, None)\n",
    "episode = pkyLoader.dataProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-11-1c279c10f238>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-1c279c10f238>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [past_agents_traj, past_agents_traj_len, future_agents_traj,\\\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "[past_agents_traj, past_agents_traj_len, future_agents_traj,\\\n",
    "future_agents_traj_len, future_agent_masks,\\\n",
    "np.array(decode_start_vel), np.array(decode_start_pos),\\\n",
    "map_image, prior, scene_id] = episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterization_q10.generator_dev import NusLoaderQ10\n",
    "\n",
    "DATAROOT='/datasets/nuscene/v1.0-mini'\n",
    "\n",
    "sampling_time = 3\n",
    "agent_time = 0 # zero for static mask, non-zero for overlap\n",
    "\n",
    "layer_names = ['drivable_area', 'road_segment', 'road_block',\n",
    "               'lane', 'ped_crossing', 'walkway', 'stop_line',\n",
    "               'carpark_area', 'road_divider', 'lane_divider']\n",
    "colors = [(255, 255, 255), (100, 255, 255), (255, 100, 255),\n",
    "          (255, 255, 100), (100, 100, 255), (100, 255, 100), (255, 100, 100),\n",
    "          (100, 100, 100), (50, 100, 50), (200, 50, 50),]\n",
    "\n",
    "dataset = NusLoaderQ10(\n",
    "    root=DATAROOT, \n",
    "    sampling_time=sampling_time, \n",
    "    agent_time=agent_time, \n",
    "    layer_names=layer_names, \n",
    "    colors=colors,\n",
    "    resolution=0.1,\n",
    "    meters_ahead=25,\n",
    "    meters_behind=25,\n",
    "    meters_left=25,\n",
    "    meters_right=25)\n",
    "\n",
    "print(\"num_samples: {}\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.thres_min = -1\n",
    "dataset.thres_max = 99999\n",
    "\n",
    "map_masks, map_img, agent_mask, xy_local, \\\n",
    "virtual_mask, virtual_xy_local, idx = dataset[190] # 100th sample\n",
    "\n",
    "agent_past = xy_local[0]\n",
    "agent_future = xy_local[1]\n",
    "agent_translation = xy_local[2]\n",
    "\n",
    "virtual_past = virtual_xy_local[0]\n",
    "virtual_future = virtual_xy_local[1]\n",
    "virtual_translation = virtual_xy_local[2]\n",
    "\n",
    "print(map_masks.shape)\n",
    "print(agent_mask.shape)\n",
    "print(virtual_mask.shape)\n",
    "\n",
    "print(len(agent_past))\n",
    "print(len(virtual_past))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(idx, thres_min, thres_max):\n",
    "    global dataset, map_masks, map_img, agent_mask, xy_local,\\\n",
    "    virtual_mask, virtual_xy_local,\\\n",
    "    agent_past, agent_future, agent_translation,\\\n",
    "    virtual_past, virtual_future, virtual_translation\n",
    "    \n",
    "    dataset.thres_min = thres_min\n",
    "    dataset.thres_max = thres_max\n",
    "    \n",
    "    map_masks, map_img, agent_mask, xy_local, \\\n",
    "    virtual_mask, virtual_xy_local, idx = dataset[idx]\n",
    "    \n",
    "    agent_past = xy_local[0]\n",
    "    agent_future = xy_local[1]\n",
    "    agent_translation = xy_local[2] \n",
    "    virtual_past = virtual_xy_local[0]\n",
    "    virtual_future = virtual_xy_local[1]\n",
    "    virtual_translation = virtual_xy_local[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "p_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([23.0582], [27.3226]),\n",
    "    transforms.Lambda(lambda x: F.log_softmax(x.reshape(-1), dim=0).reshape(x.shape[1:]))\n",
    "])\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([23.0582], [27.3226])\n",
    "])\n",
    "\n",
    "def generateDistanceMaskFromColorMap(src, scene_size=(64, 64)):\n",
    "    img = cv2.resize(src, scene_size)\n",
    "    raw_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(raw_image, 100, 255, cv2.THRESH_BINARY)\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    raw_image = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)\n",
    "\n",
    "    raw_map_image = cv2.resize(raw_image.astype(np.float32), dsize=(100, 100), interpolation=cv2.INTER_LINEAR)\n",
    "    raw_map_image[raw_map_image < 0] = 0 # Uniform on drivable area\n",
    "    raw_map_image = raw_map_image.max() - raw_map_image # Invert values so that non-drivable area has smaller values\n",
    "\n",
    "    image = img_transform(raw_image)\n",
    "    prior = p_transform(raw_map_image)\n",
    "\n",
    "    return image, prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(idx, thres_min, thres_max):\n",
    "    global dataset, map_masks, map_img, agent_mask, xy_local,\\\n",
    "    virtual_mask, virtual_xy_local,\\\n",
    "    agent_past, agent_future, agent_translation,\\\n",
    "    virtual_past, virtual_future, virtual_translation\n",
    "    \n",
    "    dataset.thres_min = thres_min\n",
    "    dataset.thres_max = thres_max\n",
    "    \n",
    "    map_masks, map_img, agent_mask, xy_local, \\\n",
    "    virtual_mask, virtual_xy_local, idx = dataset[idx]\n",
    "    \n",
    "    agent_past = xy_local[0]\n",
    "    agent_future = xy_local[1]\n",
    "    agent_translation = xy_local[2] \n",
    "    virtual_past = virtual_xy_local[0]\n",
    "    virtual_future = virtual_xy_local[1]\n",
    "    virtual_translation = virtual_xy_local[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProcessing(virtual=False): \n",
    "    global map_masks, agent_past, agent_future, agent_translation, virtual_past, virtual_future, virtual_translation\n",
    "    \n",
    "    scene_id = idx\n",
    "\n",
    "    # map mask & prior mask\n",
    "    map_image, prior = generateDistanceMaskFromColorMap(map_masks[0], scene_size=(64, 64))\n",
    "\n",
    "    # agent mask\n",
    "    past_agents_traj, past_agents_traj_len, future_agents_traj, future_agents_traj_len, \\\n",
    "    future_agent_masks, decode_start_vel, decode_start_pos = get_agent_mask(agent_past, agent_future, agent_translation)\n",
    "\n",
    "    # virtual agent mask\n",
    "    past_agents_traj2, past_agents_traj_len2, future_agents_traj2, future_agents_traj_len2, \\\n",
    "    future_agent_masks2, decode_start_vel2, decode_start_pos2 = get_agent_mask(virtual_past, virtual_future, virtual_translation)\n",
    "\n",
    "    episode = None\n",
    "    if virtual:\n",
    "        episode = [past_agents_traj2, past_agents_traj_len2, future_agents_traj2, \n",
    "                   future_agents_traj_len2, future_agent_masks2,\n",
    "                   np.array(decode_start_vel2), np.array(decode_start_pos2), \n",
    "                   map_image, prior, scene_id]\n",
    "    else:\n",
    "        episode = [past_agents_traj, past_agents_traj_len, future_agents_traj, \n",
    "                   future_agents_traj_len, future_agent_masks,\n",
    "                   np.array(decode_start_vel), np.array(decode_start_pos),\n",
    "                   map_image, prior, scene_id]\n",
    "\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCurve(points):\n",
    "    if len(points) < 3:\n",
    "        return 0\n",
    "    curvature_list = np.empty(0)\n",
    "    for i in range(len(points) - 2):\n",
    "        A = points[i]\n",
    "        B = points[i + 1]\n",
    "        C = points[i + 2]\n",
    "        curvature_value = abs(curvature(A, B, C))\n",
    "        curvature_list = np.append(curvature_list, curvature_value)\n",
    "    return np.average(curvature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGeneration(thres=0.02, curved_ratio=0.3):\n",
    "    episodes = []\n",
    "    \n",
    "    num_linear = 0\n",
    "    num_curved = 0\n",
    "    \n",
    "    N = len(dataset)\n",
    "    \n",
    "    # count the number of curved agents\n",
    "    global agent_past\n",
    "    for idx in range(N):\n",
    "        load_data(idx, -1, thres)\n",
    "        num_linear += len(agent_past)\n",
    "        load_data(idx, thres, 99999)\n",
    "        num_curved += len(agent_past)\n",
    "    \n",
    "    # original data\n",
    "    for idx in range(N):\n",
    "        load_data(idx, -1, 99999)\n",
    "        episode = dataProcessing()\n",
    "        if sum(episode[4]) > 0:\n",
    "            episodes.append(episode)\n",
    "    \n",
    "    # generate curved data\n",
    "    curved_target = (num_linear/(1-curved_ratio)) * curved_ratio - num_curved\n",
    "    index = 0\n",
    "    while curved_target > 0:\n",
    "        load_data(index, thres, 99999)\n",
    "        episode = dataProcessing(virtual=True)\n",
    "        \n",
    "        n = sum(episode[4])\n",
    "        \n",
    "        if n > 0:\n",
    "            episodes.append(episode)\n",
    "            curved_target -= n\n",
    "            \n",
    "        index += 1\n",
    "        if index > N - 1:\n",
    "            index = 0\n",
    "    \n",
    "    return episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.02\n",
    "curved_ratio = 0.3\n",
    "\n",
    "# parsed_data = dataGeneration(thres=thres, curved_ratio=curved_ratio)\n",
    "\n",
    "# print(\"Number of Data: {}\".format(len(parsed_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Examples: 1208\n"
     ]
    }
   ],
   "source": [
    "dataset_pky, data_loader_pky = pky.load_pky()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_images_pky, log_prior_pky, \\\n",
    "    agent_masks_pky, \\\n",
    "    num_src_trajs_pky, src_trajs_pky, src_lens_pky, src_len_idx_pky, \\\n",
    "    num_tgt_trajs_pky, tgt_trajs_pky, tgt_lens_pky, tgt_len_idx_pky, \\\n",
    "    tgt_two_mask_pky, tgt_three_mask_pky, \\\n",
    "    decode_start_vel_pky, decode_start_pos_pky, scene_id_pky = np.arange(16)\n",
    "\n",
    "for b, batch in enumerate(data_loader_pky):\n",
    "    scene_images_pky, log_prior_pky, \\\n",
    "    agent_masks_pky, \\\n",
    "    num_src_trajs_pky, src_trajs_pky, src_lens_pky, src_len_idx_pky, \\\n",
    "    num_tgt_trajs_pky, tgt_trajs_pky, tgt_lens_pky, tgt_len_idx_pky, \\\n",
    "    tgt_two_mask_pky, tgt_three_mask_pky, \\\n",
    "    decode_start_vel_pky, decode_start_pos_pky, scene_id_pky = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 64, 64]),\n",
       " torch.Size([64, 100, 100]),\n",
       " torch.Size([578]),\n",
       " [],\n",
       " torch.Size([64]),\n",
       " torch.Size([578, 4, 2]),\n",
       " torch.Size([578]),\n",
       " torch.Size([2263]),\n",
       " [],\n",
       " torch.Size([64]),\n",
       " torch.Size([526, 6, 2]),\n",
       " torch.Size([526]),\n",
       " torch.Size([3039]),\n",
       " [],\n",
       " torch.Size([526]),\n",
       " torch.Size([526]),\n",
       " [],\n",
       " torch.Size([578, 2]),\n",
       " torch.Size([578, 2]),\n",
       " (64, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_images.shape, log_prior.shape, agent_masks.shape, \\\n",
    "[], \\\n",
    "num_src_trajs.shape, src_trajs.shape, src_lens.shape, src_len_idx.shape, \\\n",
    "[], \\\n",
    "num_tgt_trajs.shape, tgt_trajs.shape, tgt_lens.shape, tgt_len_idx.shape, \\\n",
    "[], \\\n",
    "tgt_two_mask.shape, tgt_three_mask.shape, \\\n",
    "[], \\\n",
    "decode_start_vel.shape, decode_start_pos.shape, scene_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True, False,  True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_masks_pky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 64, 64]),\n",
       " torch.Size([64, 100, 100]),\n",
       " torch.Size([1289]),\n",
       " [],\n",
       " torch.Size([64]),\n",
       " torch.Size([1289, 4, 2]),\n",
       " torch.Size([1289]),\n",
       " torch.Size([4497]),\n",
       " [],\n",
       " torch.Size([64]),\n",
       " torch.Size([1289, 6, 2]),\n",
       " torch.Size([1289]),\n",
       " torch.Size([7038]),\n",
       " [],\n",
       " torch.Size([1289]),\n",
       " torch.Size([1289]),\n",
       " [],\n",
       " torch.Size([1289, 2]),\n",
       " torch.Size([1289, 2]),\n",
       " (64,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_images_pky.shape, log_prior_pky.shape, agent_masks_pky.shape, \\\n",
    "[], \\\n",
    "num_src_trajs_pky.shape, src_trajs_pky.shape, src_lens_pky.shape, src_len_idx_pky.shape, \\\n",
    "[], \\\n",
    "num_tgt_trajs_pky.shape, tgt_trajs_pky.shape, tgt_lens_pky.shape, tgt_len_idx_pky.shape, \\\n",
    "[], \\\n",
    "tgt_two_mask_pky.shape, tgt_three_mask_pky.shape, \\\n",
    "[], \\\n",
    "decode_start_vel_pky.shape, decode_start_pos_pky.shape, scene_id_pky.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_cmu[0]), len(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트레이닝 데이터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) original nuscenes (with angle of routine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Generated via HD Map (with angle of routine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러와서 비율에 맞게 다시 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Generated 데이터만 (10:0, 5:5, 2:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ratio = 0.7\n",
    "\n",
    "num_data = len(dataset)\n",
    "print(num_data)\n",
    "\n",
    "shuffled = dataset.copy()\n",
    "random.shuffle(shuffled)\n",
    "\n",
    "split = int(num_data*ratio)\n",
    "\n",
    "train = shuffled[:split]\n",
    "val = shuffled[split:]\n",
    "\n",
    "with open(filename+'_train', 'wb') as f:\n",
    "    pickle.dump(train, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(filename+'_val', 'wb') as f:\n",
    "    pickle.dump(val, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Original 데이터만 (10:0, 5:5, 2:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 둘이 섞어서 (5:5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelpro",
   "language": "python",
   "name": "intelpro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
